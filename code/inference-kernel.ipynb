{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from io import StringIO\n",
    "from csv import writer\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import IPython\n",
    "import IPython.display\n",
    "# import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = (\n",
    "    (Path('../input/fat2019ssl4multistage/work/work'), 'stage-2_fold-{fold}.pkl'),\n",
    "    (Path('../input/fat2019ssl4multistage/work/work'), 'stage-10_fold-{fold}.pkl'),\n",
    "    (Path('../input/fat2019ssl4multistage/work/work'), 'stage-11_fold-{fold}.pkl'),\n",
    "    (Path('../input/fat2019ssl8vgg16full/work/work'), 'stage-2_fold-{fold}.pkl'),\n",
    "    (Path('../input/fat2019ssl8vgg16full/work/work'), 'stage-10_fold-{fold}.pkl'),\n",
    "    (Path('../input/fat2019ssl8vgg16full/work/work'), 'stage-11_fold-{fold}.pkl'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA_SHIFT = 48  # TTA: predict every TTA_SHIFT\n",
    "n_splits = 10\n",
    "DATA = Path('../input/freesound-audio-tagging-2019')\n",
    "DATA_TEST = DATA/'test'\n",
    "CSV_SUBMISSION = DATA/'sample_submission.csv'\n",
    "test_df = pd.read_csv(CSV_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visually check everything is present in datasets\n",
    "# for work, name in models_list:\n",
    "#     print('-'*10, work, name, '-'*10)\n",
    "#     !ls {work}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(conf, pathname, trim_long_data):\n",
    "    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n",
    "    # trim silence\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n",
    "    # make it unified length to conf.samples\n",
    "    if len(y) > conf.samples: # long enough\n",
    "        if trim_long_data:\n",
    "            y = y[0:0+conf.samples]\n",
    "    else: # pad blank\n",
    "        padding = conf.samples - len(y)    # add padding at both ends\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n",
    "    return y\n",
    "\n",
    "def audio_to_melspectrogram(conf, audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(audio, \n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "def show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n",
    "    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n",
    "                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n",
    "                            fmin=conf.fmin, fmax=conf.fmax)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def read_as_melspectrogram(conf, pathname, trim_long_data, debug_display=False):\n",
    "    x = read_audio(conf, pathname, trim_long_data)\n",
    "    mels = audio_to_melspectrogram(conf, x)\n",
    "    if debug_display:\n",
    "        IPython.display.display(IPython.display.Audio(x, rate=conf.sampling_rate))\n",
    "        show_melspectrogram(conf, mels)\n",
    "    return mels\n",
    "\n",
    "\n",
    "class conf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    duration = 2\n",
    "    hop_length = 347*duration # to make time steps 128\n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    n_mels = 128\n",
    "    n_fft = n_mels * 20\n",
    "    samples = sampling_rate * duration\n",
    "\n",
    "# example\n",
    "# x = read_as_melspectrogram(conf, DATA_CURATED/'0006ae4e.wav', trim_long_data=False, debug_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    Xstd = (X - mean) / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Scale to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "def convert_wav_to_image(df, source, img_dest):\n",
    "    print(f'Converting {source} -> {img_dest}')\n",
    "    X = []\n",
    "    for i, row in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "        x = read_as_melspectrogram(conf, source/str(row.fname), trim_long_data=False)\n",
    "        x_color = mono_to_color(x)\n",
    "        X.append(x_color)\n",
    "#     pickle.dump(X, open(img_dest, 'wb'))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ../input/freesound-audio-tagging-2019/test -> None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2431b368bf6443c8a44187f95c2b548f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = convert_wav_to_image(test_df, source=DATA_TEST, img_dest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMixUpCallback(LearnerCallback):\n",
    "    def __init__(self, learn:Learner):\n",
    "        super().__init__(learn)\n",
    "#         self.num_mask=2\n",
    "        self.masking_max_percentage=0.25\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if not train: return\n",
    "\n",
    "        shuffle = torch.randperm(last_target.size(0)).to(last_input.device)\n",
    "        x1, y1 = last_input[shuffle], last_target[shuffle]\n",
    "\n",
    "        batch_size, channels, height, width = last_input.size()\n",
    "        h_percentage = np.random.uniform(low=0., high=self.masking_max_percentage, size=batch_size)\n",
    "        w_percentage = np.random.uniform(low=0., high=self.masking_max_percentage, size=batch_size)\n",
    "#         alpha = self.num_mask * (h_percentage + w_percentage) - (self.num_mask*self.num_mask) * ((h_percentage * w_percentage))\n",
    "        alpha = (h_percentage + w_percentage) - (h_percentage * w_percentage)\n",
    "        alpha = last_input.new(alpha)\n",
    "        alpha = alpha.unsqueeze(1)\n",
    "        \n",
    "        new_input = last_input.clone()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            h_mask = int(h_percentage[i] * height)\n",
    "            h = int(np.random.uniform(0.0, height - h_mask))\n",
    "            new_input[i, :, h:h + h_mask, :] = x1[i, :, h:h + h_mask, :]\n",
    "\n",
    "            w_mask = int(w_percentage[i] * width)\n",
    "            w = int(np.random.uniform(0.0, width - w_mask))\n",
    "            new_input[i, :, :, w:w + w_mask] = x1[i, :, :, w:w + w_mask]\n",
    "        \n",
    "#         new_target = torch.max(last_target, y1)\n",
    "        new_target = (1-alpha) * last_target + alpha*y1\n",
    "        return {'last_input': new_input, 'last_target': new_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class\n",
    "\n",
    "\n",
    "# Accumulator object version.\n",
    "\n",
    "class lwlrap_accumulator(object):\n",
    "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n",
    "\n",
    "  def __init__(self):\n",
    "    self.num_classes = 0\n",
    "    self.total_num_samples = 0\n",
    "  \n",
    "  def accumulate_samples(self, batch_truth, batch_scores):\n",
    "    \"\"\"Cumulate a new batch of samples into the metric.\n",
    "    \n",
    "    Args:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean\n",
    "        ground-truth of presence of that class in that sample for this batch.\n",
    "      scores: np.array of (num_samples, num_classes) giving the \n",
    "        classifier-under-test's real-valued score for each class for each\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    assert batch_scores.shape == batch_truth.shape\n",
    "    num_samples, num_classes = batch_truth.shape\n",
    "    if not self.num_classes:\n",
    "      self.num_classes = num_classes\n",
    "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
    "      self._per_class_cumulative_count = np.zeros(self.num_classes, \n",
    "                                                  dtype=np.int)\n",
    "    assert num_classes == self.num_classes\n",
    "    for truth, scores in zip(batch_truth, batch_scores):\n",
    "      pos_class_indices, precision_at_hits = (\n",
    "        _one_sample_positive_class_precisions(scores, truth))\n",
    "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
    "        precision_at_hits)\n",
    "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
    "    self.total_num_samples += num_samples\n",
    "\n",
    "  def per_class_lwlrap(self):\n",
    "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
    "    return (self._per_class_cumulative_precision / \n",
    "            np.maximum(1, self._per_class_cumulative_count))\n",
    "\n",
    "  def per_class_weight(self):\n",
    "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
    "    return (self._per_class_cumulative_count / \n",
    "            float(np.sum(self._per_class_cumulative_count)))\n",
    "\n",
    "  def overall_lwlrap(self):\n",
    "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
    "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lwlrap(Callback):\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.accumulator = lwlrap_accumulator()\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        self.accumulator.accumulate_samples(last_target.cpu().numpy(), torch.sigmoid(last_output).cpu().numpy())\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics, self.accumulator.overall_lwlrap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        return x\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=1000): # <======== modificaition to comply fast.ai\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=3, out_channels=64),\n",
    "            ConvBlock(in_channels=64, out_channels=128),\n",
    "            ConvBlock(in_channels=128, out_channels=256),\n",
    "            ConvBlock(in_channels=256, out_channels=512),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # <======== modificaition to comply fast.ai\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        #x = torch.mean(x, dim=3)   # <======== modificaition to comply fast.ai\n",
    "        #x, _ = torch.max(x, dim=2) # <======== modificaition to comply fast.ai\n",
    "        x = self.avgpool(x)         # <======== modificaition to comply fast.ai\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! use globals CUR_X_FILES, CUR_X\n",
    "def open_fat2019_image(fn, convert_mode, after_open)->Image:\n",
    "    # open\n",
    "    fname = fn.split('/')[-1]\n",
    "    if '!' in fname:\n",
    "        fname, crop_x = fname.split('!')\n",
    "        crop_x = int(crop_x)\n",
    "    else:\n",
    "        crop_x = -1\n",
    "    idx = CUR_X_FILES.index(fname)\n",
    "    x = CUR_X[idx]\n",
    "    # crop\n",
    "    base_dim, time_dim, _ = x.shape\n",
    "    if crop_x == -1:\n",
    "        crop_x = random.randint(0, time_dim - base_dim)\n",
    "    x = x[0:base_dim, crop_x:crop_x+base_dim, :]\n",
    "    x = np.transpose(x, (1, 0, 2))\n",
    "    x = np.transpose(x, (2, 1, 0))\n",
    "    # standardize\n",
    "    return Image(torch.from_numpy(x.astype(np.float32, copy=False)).div_(255))\n",
    "\n",
    "\n",
    "vision.data.open_image = open_fat2019_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_X_FILES, CUR_X = list(test_df.fname.values), X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32cfc323413459785abf854a319dd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = StringIO()\n",
    "csv_writer = writer(output)\n",
    "csv_writer.writerow(test_df.columns)\n",
    "\n",
    "for _, row in tqdm_notebook(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    idx = CUR_X_FILES.index(row.fname)\n",
    "    time_dim = CUR_X[idx].shape[1]\n",
    "    s = math.ceil((time_dim-conf.n_mels) / TTA_SHIFT) + 1\n",
    "    \n",
    "    fname = row.fname\n",
    "    for crop_x in [int(np.around((time_dim-conf.n_mels)*x/(s-1))) if s != 1 else 0 for x in range(s)]:\n",
    "        row.fname = fname + '!' + str(crop_x)\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "output.seek(0)\n",
    "test_df_multi = pd.read_csv(output)\n",
    "\n",
    "del row, test_df, output, csv_writer; gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='113' class='' max='207', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      54.59% [113/207 00:09<00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ImageList.from_df(test_df_multi, models_list[0][0])\n",
    "\n",
    "for model_nb, (work, name) in enumerate(models_list):\n",
    "    for fold in range(n_splits):\n",
    "        learn = load_learner(work, name.format(fold=fold), test=test)\n",
    "        preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "        preds = preds.cpu().numpy()\n",
    "        if (fold == 0) and (model_nb == 0):\n",
    "            predictions = preds\n",
    "        else:\n",
    "            predictions += preds\n",
    "\n",
    "predictions /= (n_splits * len(models_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_multi[learn.data.classes] = predictions\n",
    "test_df_multi['fname'] = test_df_multi.fname.apply(lambda x: x.split('!')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_df_multi.infer_objects().groupby('fname').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.105709</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.194247</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.022429</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0.262763</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.008760</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.417701</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.039275</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.097219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.037562</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.466026</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.001990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.045293</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.917425</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.007289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.630423</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.200024</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...                   0.001348\n",
       "1  0012633b.wav        ...                   0.097219\n",
       "2  001ed5f1.wav        ...                   0.001990\n",
       "3  00294be0.wav        ...                   0.007289\n",
       "4  003fde7a.wav        ...                   0.001265\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fname\n",
       "000ccb97.wav                           Bass_drum\n",
       "0012633b.wav                          Motorcycle\n",
       "001ed5f1.wav                                 Run\n",
       "00294be0.wav                                Purr\n",
       "003fde7a.wav                        Bicycle_bell\n",
       "0040ccc9.wav                     Electric_guitar\n",
       "0046b732.wav                                Meow\n",
       "004f3bbc.wav                         Bass_guitar\n",
       "00526050.wav                           Bass_drum\n",
       "00559da4.wav                   Zipper_(clothing)\n",
       "00582bbe.wav                               Knock\n",
       "0064aedf.wav                Drawer_open_or_close\n",
       "0065512b.wav                                Slam\n",
       "006a91d2.wav                              Stream\n",
       "006ea9ee.wav                               Strum\n",
       "006f9dca.wav                Water_tap_and_faucet\n",
       "007450dc.wav                           Screaming\n",
       "00979c8a.wav                                Purr\n",
       "00992464.wav                  Fill_(with_liquid)\n",
       "00b44a8a.wav              Cutlery_and_silverware\n",
       "00bfaaaf.wav                                Gasp\n",
       "00cf9680.wav                              Stream\n",
       "00eae94d.wav        Bathtub_(filling_or_washing)\n",
       "011ec5b8.wav                Drawer_open_or_close\n",
       "013200dc.wav                                Fart\n",
       "01440c2e.wav                           Harmonica\n",
       "01567a3d.wav                      Microwave_oven\n",
       "0163d203.wav                                Purr\n",
       "017c24b2.wav                                Meow\n",
       "01a992c5.wav                             Cricket\n",
       "                              ...               \n",
       "406306b6.wav                               Strum\n",
       "406a1cc1.wav                               Knock\n",
       "406ade5e.wav                 Trickle_and_dribble\n",
       "4093913f.wav                        Toilet_flush\n",
       "40957335.wav                                Gasp\n",
       "4098028d.wav                   Computer_keyboard\n",
       "40afd1b3.wav                          Whispering\n",
       "40c1ed87.wav                       Keys_jangling\n",
       "40c50046.wav                   Computer_keyboard\n",
       "40d0726d.wav                      Car_passing_by\n",
       "40dd1274.wav    Female_speech_and_woman_speaking\n",
       "40e25750.wav              Burping_and_eructation\n",
       "410837eb.wav                     Acoustic_guitar\n",
       "410c2138.wav                        Toilet_flush\n",
       "411993fd.wav                              Hi-hat\n",
       "413b5427.wav                           Harmonica\n",
       "41522a65.wav                     Chirp_and_tweet\n",
       "415f4c8f.wav              Cutlery_and_silverware\n",
       "41759973.wav                              Stream\n",
       "419271cc.wav                        Bicycle_bell\n",
       "4195cb1a.wav               Marimba_and_xylophone\n",
       "41af688a.wav                                Fart\n",
       "41c60bba.wav                      Microwave_oven\n",
       "41cfee6d.wav                           Accordion\n",
       "41f16193.wav                                Slam\n",
       "41f1ea4a.wav     Traffic_noise_and_roadway_noise\n",
       "41f86bc4.wav                        Toilet_flush\n",
       "4215309a.wav                            Scissors\n",
       "4248d196.wav                            Applause\n",
       "42542036.wav            Race_car_and_auto_racing\n",
       "Length: 1120, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.set_index('fname').idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Done in', time.time() - start_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
